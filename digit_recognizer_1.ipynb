{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load (downloaded if needed) the MNIST dataset\n",
    "\n",
    "train = pd.read_csv('./datasets/train.csv')\n",
    "test = pd.read_csv('./datasets/test.csv')\n",
    "\n",
    "#y_train = np.array(df['label'].values)\n",
    "#print(y_train)\n",
    "\n",
    "X_train = (train.iloc[:,1:].values.astype('float32'))\n",
    "y_train = (train.iloc[:,0].values.astype('int32'))\n",
    "y_train = np.tile(y_train, (1, 1))\n",
    "X_test = test.values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network:\n",
    "    def __init__(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.m = X_train.shape[0]\n",
    "        self.input_layer_size = X_train.shape[1]\n",
    "        self.hidden_layer_size = 25\n",
    "        self.output_layer_size = 10\n",
    "        self.epsilon = []\n",
    "        self.theta1 = 0\n",
    "        self.theta2 = 0\n",
    "        self.J = 0\n",
    "        self.grad = 0\n",
    "        self.num_labels = 10\n",
    "        self.grad = 0\n",
    "        self.counter = 0\n",
    "        \n",
    "    def randInit(self, X, y):\n",
    "        ils = self.input_layer_size\n",
    "        hls = self.hidden_layer_size\n",
    "        ols = self.output_layer_size\n",
    "        \n",
    "        L_in = ils\n",
    "        L_out = hls\n",
    "        \n",
    "        self.epsilon.append(math.sqrt(6) / math.sqrt(L_in + L_out))\n",
    "        \n",
    "        L_in = hls\n",
    "        L_out = ols\n",
    "        \n",
    "        self.epsilon.append(math.sqrt(6) / math.sqrt(L_in + L_out))\n",
    "        \n",
    "        #The theta values are of the form S(j + 1) x S(j) + 1 where S(j) i sthe size of the layer at j\n",
    "        \n",
    "        self.theta1 = np.dot(np.random.rand(hls, ils + 1), (2 * self.epsilon[0])) - self.epsilon[0]\n",
    "        \n",
    "        self.theta2 = np.dot(np.random.rand(ols, hls + 1), (2 * self.epsilon[1])) - self.epsilon[1]\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        return ( 1/(1 + np.exp(-z)))\n",
    "    \n",
    "    def sigmoidPrime(self, z):\n",
    "        z = self.sigmoid(z)\n",
    "        return np.multiply(z, (1-z))\n",
    "    \n",
    "    def costFunction(self, nn_params, ils, hls, num_labels, X, y, lam):\n",
    "        y = y.T\n",
    "        self.counter+=1\n",
    "        \n",
    "        theta1 = np.reshape(nn_params[:hls * (ils + 1)], \\\n",
    "                     (hls, ils + 1), order='F')\n",
    "        \n",
    "        theta2 = np.reshape(nn_params[hls * (ils + 1):], \\\n",
    "                     (num_labels, hls + 1), order='F')\n",
    "        \n",
    "        #Foward propogation\n",
    "        a1 = np.hstack((np.ones((self.m, 1)), X ))\n",
    "        \n",
    "        z2 = np.dot(a1, theta1.T)\n",
    "        \n",
    "        a2 = self.sigmoid(z2)\n",
    "        a2 = np.hstack((np.ones((a2.shape[0], 1)), a2))\n",
    "        \n",
    "        z3 = np.dot(a2, theta2.T)\n",
    "        \n",
    "        a3 = self.sigmoid(z3)\n",
    "        \n",
    "        #Cost function\n",
    "        \n",
    "        numLabels_temp = np.tile([i for i in range(10)], (self.m, 1) )\n",
    "        \n",
    "        yMatrix_temp = np.tile(y, (1,self.num_labels) )\n",
    "        \n",
    "        yMatrix = np.equal(numLabels_temp, yMatrix_temp)\n",
    "        \n",
    "        cost_no_reg = np.sum(np.multiply(yMatrix, np.log(a3)) + np.multiply((1-yMatrix), np.log(1 - a3)))\n",
    "        \n",
    "        reg = (lam / (2*self.m)) * ((np.sum(np.square(theta1[:, 1:])) + np.sum(np.square(theta2[:, 1:])))) ** 2\n",
    "        \n",
    "        self.J =  ((-1/self.m) * cost_no_reg) + reg\n",
    "        \n",
    "        self.grad = self.backProp(theta1, theta2)\n",
    "        \n",
    "        print(self.counter, \") Cost: \", self.J)\n",
    "        \n",
    "        return self.J, self.grad\n",
    "        \n",
    "    def backProp(self, theta1, theta2):\n",
    "        X = self.X_train\n",
    "        y = self.y_train\n",
    "        y = y.T\n",
    "        lam = 0\n",
    "        \n",
    "        numLabels_temp = np.tile([i for i in range(10)], (self.m, 1) )\n",
    "        \n",
    "        yMatrix_temp = np.tile(y, (1,self.num_labels) )\n",
    "        \n",
    "        yMatrix = np.equal(numLabels_temp, yMatrix_temp)\n",
    "        \n",
    "        delta2 = 0\n",
    "        delta1 = 0\n",
    "        \n",
    "        for i in range(0, self.m):\n",
    "            \n",
    "            a1 = np.append(1, X[i, :] )\n",
    "            a1 = a1.reshape(1, a1.size)\n",
    "        \n",
    "            z2 = np.dot(a1, theta1.T)\n",
    "\n",
    "            a2 = self.sigmoid(z2)\n",
    "            a2 = np.append(1, a2)\n",
    "            a2 = a2.reshape(1, a2.size)\n",
    "\n",
    "            z3 = np.dot(a2, theta2.T)\n",
    "\n",
    "            a3 = self.sigmoid(z3)\n",
    "            a3 = a3.reshape(1, a3.size)\n",
    "            \n",
    "            yMatrix_i = yMatrix[i, :]\n",
    "            yMatrix_i.reshape(1, yMatrix_i.size)\n",
    "            \n",
    "            delta3_i = np.subtract(a3, yMatrix_i)\n",
    "            \n",
    "            g2 = self.sigmoidPrime(np.insert(z2, 0, 1, axis=1))\n",
    "            g2 = g2.reshape(1, g2.size)\n",
    "            \n",
    "            delta2_i = np.multiply(np.dot(theta2.T, delta3_i.T), g2.T)\n",
    "            delta2_i = delta2_i[1:].T\n",
    "            \n",
    "            delta2 = delta2 + np.dot(delta3_i.T, a2)\n",
    "            \n",
    "            delta1 = delta1 + np.dot(delta2_i.T, a1)\n",
    "            \n",
    "        #theta1_no_bias = np.multiply((lam/self.m), theta1[:, 1:])\n",
    "        #theta2_no_bias = np.multiply((lam/self.m), theta2[:, 1:])\n",
    "        \n",
    "        #theta1_bias = np.multiply((1/self.m), delta1[:, 1])\n",
    "        #theta1_bias = theta1_bias.reshape(theta1_bias.size, 1)\n",
    "        \n",
    "        #theta2_bias = np.multiply((1/self.m), delta2[:, 1])\n",
    "        #theta2_bias = theta2_bias.reshape(theta2_bias.size, 1)\n",
    "        \n",
    "        #Theta1_grad = np.concatenate((theta1_bias, np.add(np.multiply((1/self.m), delta1[:, 1:]), theta1_no_bias)), axis=1)\n",
    "        #Theta2_grad = np.concatenate((theta2_bias, np.add(np.multiply((1/self.m), delta2[:, 1:]), theta2_no_bias)), axis=1)\n",
    "        \n",
    "        #self.grad = np.concatenate((Theta1_grad.reshape(Theta1_grad.size, order='F'), Theta2_grad.reshape(Theta2_grad.size, order='F')))\n",
    "        \n",
    "        Theta1_grad = delta1 / self.m\n",
    "        Theta2_grad = delta2 / self.m\n",
    "        \n",
    "        Theta1_grad_unregularized = np.copy(Theta1_grad)\n",
    "        Theta2_grad_unregularized = np.copy(Theta2_grad)\n",
    "        Theta1_grad += (float(lam)/self.m)*theta1\n",
    "        Theta2_grad += (float(lam)/self.m)*theta2\n",
    "        Theta1_grad[:,0] = Theta1_grad_unregularized[:,0]\n",
    "        Theta2_grad[:,0] = Theta2_grad_unregularized[:,0]\n",
    "        \n",
    "        self.grad = np.concatenate((Theta1_grad.reshape(Theta1_grad.size, order='F'), Theta2_grad.reshape(Theta2_grad.size, order='F')))\n",
    "        \n",
    "        return self.grad\n",
    "        \n",
    "    def train(self, theta1, theta2, nn_params, X, y):\n",
    "        \n",
    "        print(self.J,)\n",
    "        print('Training Neural Network...')\n",
    "        #maxiter = 20\n",
    "        #maxiter = 30\n",
    "        maxiter = 100\n",
    "        #maxiter = 5\n",
    "        \n",
    "        lambda_reg = 0.1\n",
    "        \n",
    "        nn_params = np.concatenate((theta1.reshape(theta1.size, order='F'), theta2.reshape(theta2.size, order='F')))\n",
    "        \n",
    "        myargs = (self.input_layer_size, self.hidden_layer_size, self.num_labels, X, y, lambda_reg)\n",
    "        results = minimize(self.costFunction, x0=nn_params, args=myargs, options={'disp': True, 'maxiter':maxiter}, method=\"L-BFGS-B\", jac=True)\n",
    "\n",
    "        nn_params = results[\"x\"]\n",
    "\n",
    "        # Obtain Theta1 and Theta2 back from nn_params\n",
    "        Theta1 = np.reshape(nn_params[:self.hidden_layer_size * (self.input_layer_size + 1)], \\\n",
    "                         (self.hidden_layer_size, self.input_layer_size + 1), order='F')\n",
    "\n",
    "        Theta2 = np.reshape(nn_params[self.hidden_layer_size * (self.input_layer_size + 1):], \\\n",
    "                         (self.num_labels, self.hidden_layer_size + 1), order='F')\n",
    "\n",
    "        print('Program paused. Press enter to continue.\\n')\n",
    "        return Theta1,Theta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Training Neural Network...\n",
      "1 ) Cost:  7.4039303196073325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akil313\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:40: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 ) Cost:  4.478014856136297\n",
      "3 ) Cost:  3.65755737531258\n",
      "4 ) Cost:  3.243720669227001\n",
      "5 ) Cost:  3.0696036185922977\n",
      "6 ) Cost:  3.004656038683013\n",
      "7 ) Cost:  2.947193036907097\n",
      "8 ) Cost:  2.8365667769922887\n",
      "9 ) Cost:  2.789451168850097\n",
      "10 ) Cost:  2.6282223270012643\n",
      "11 ) Cost:  2.5065746938158444\n",
      "12 ) Cost:  2.3985592649669227\n",
      "13 ) Cost:  2.1378170726304946\n",
      "14 ) Cost:  1.9311728005642088\n",
      "15 ) Cost:  1.8535227971391328\n",
      "16 ) Cost:  1.9149775928113528\n",
      "17 ) Cost:  1.8452543492380347\n",
      "18 ) Cost:  1.8920455248229269\n",
      "19 ) Cost:  1.845181418730116\n",
      "20 ) Cost:  1.9452566557727293\n",
      "21 ) Cost:  1.8487790939418274\n",
      "22 ) Cost:  1.8453249087951455\n",
      "23 ) Cost:  1.845179949651545\n",
      "24 ) Cost:  1.845254800670534\n",
      "25 ) Cost:  1.8451863908419885\n",
      "26 ) Cost:  1.8451808689493048\n",
      "27 ) Cost:  1.845179949651545\n",
      "28 ) Cost:  2.040427288065639\n",
      "29 ) Cost:  1.8523277730004177\n",
      "30 ) Cost:  1.845740058600095\n",
      "31 ) Cost:  1.8452443625887844\n",
      "32 ) Cost:  1.8451877468644098\n",
      "33 ) Cost:  1.8451808961058347\n",
      "34 ) Cost:  1.8451800645676788\n",
      "35 ) Cost:  1.8451799636048396\n",
      "36 ) Cost:  1.8451799513457827\n",
      "37 ) Cost:  1.8451799498572634\n",
      "38 ) Cost:  1.845179949676524\n",
      "39 ) Cost:  1.8451799496545787\n",
      "40 ) Cost:  1.8451799496519132\n",
      "41 ) Cost:  1.8451799496515902\n",
      "42 ) Cost:  1.8451799496515506\n",
      "43 ) Cost:  1.8451799496515466\n",
      "44 ) Cost:  1.845179949651545\n",
      "45 ) Cost:  1.845179949651546\n",
      "46 ) Cost:  1.8451799496515453\n",
      "47 ) Cost:  1.845179949651545\n",
      "48 ) Cost:  1.813526679393705\n",
      "49 ) Cost:  1.79493577959876\n",
      "50 ) Cost:  1.7814077113248046\n",
      "51 ) Cost:  1.7490970304745836\n",
      "52 ) Cost:  1.7166051584033906\n",
      "53 ) Cost:  1.6709122785990254\n",
      "54 ) Cost:  1.6342065377358836\n",
      "55 ) Cost:  1.5877913951866642\n",
      "56 ) Cost:  1.5962415838813013\n",
      "57 ) Cost:  1.5693514401500732\n",
      "58 ) Cost:  1.5503953112557654\n",
      "59 ) Cost:  1.5313146308316827\n",
      "60 ) Cost:  1.5449683585208374\n",
      "61 ) Cost:  1.5282368910927642\n",
      "62 ) Cost:  1.5052646711103848\n",
      "63 ) Cost:  1.5042410499380745\n",
      "64 ) Cost:  1.5162836757200022\n",
      "65 ) Cost:  1.496986439070456\n",
      "66 ) Cost:  1.6438876607813666\n",
      "67 ) Cost:  1.4886553886209704\n",
      "68 ) Cost:  1.4842644258879831\n",
      "69 ) Cost:  1.4884153468844892\n",
      "70 ) Cost:  1.481692379900959\n",
      "71 ) Cost:  1.469276172725693\n",
      "72 ) Cost:  1.4463970708119234\n",
      "73 ) Cost:  1.4490294552177712\n",
      "74 ) Cost:  1.446184416614379\n",
      "75 ) Cost:  1.4456304135839773\n",
      "76 ) Cost:  1.4612055704713574\n",
      "77 ) Cost:  1.446535839971303\n",
      "78 ) Cost:  1.4457847289548842\n",
      "79 ) Cost:  1.445649729235349\n",
      "80 ) Cost:  1.4456333304942572\n",
      "81 ) Cost:  1.4456308762899743\n",
      "82 ) Cost:  1.4456304876081432\n",
      "83 ) Cost:  1.4456304254427557\n",
      "84 ) Cost:  1.4456304154841908\n",
      "85 ) Cost:  1.445630413888472\n",
      "86 ) Cost:  1.4456304136327707\n",
      "87 ) Cost:  1.4456304135917966\n",
      "88 ) Cost:  1.4456304135852305\n",
      "89 ) Cost:  1.445630413584178\n",
      "90 ) Cost:  1.4456304135840097\n",
      "91 ) Cost:  1.4456304135839826\n",
      "92 ) Cost:  1.4456304135839781\n",
      "93 ) Cost:  1.4456304135839781\n",
      "94 ) Cost:  1.4456304135839773\n",
      "95 ) Cost:  1.445630413583978\n",
      "96 ) Cost:  1.4338397758390127\n",
      "97 ) Cost:  1.4330074830307529\n",
      "98 ) Cost:  1.4277005886339136\n",
      "99 ) Cost:  1.4214504680883218\n",
      "100 ) Cost:  1.418553070789532\n",
      "101 ) Cost:  1.4128528187181468\n",
      "102 ) Cost:  1.4100844162824786\n",
      "103 ) Cost:  1.4075879620350626\n",
      "104 ) Cost:  1.4013873026010812\n",
      "105 ) Cost:  1.3988444250523573\n",
      "106 ) Cost:  1.3940077680759044\n",
      "107 ) Cost:  1.3879315602987914\n",
      "108 ) Cost:  1.3869398353735487\n",
      "109 ) Cost:  1.384725414836446\n",
      "110 ) Cost:  1.3759290677795144\n",
      "111 ) Cost:  1.3727889368190624\n",
      "112 ) Cost:  1.3746872079652201\n",
      "113 ) Cost:  1.3717272357953623\n",
      "114 ) Cost:  1.3698978646218862\n",
      "115 ) Cost:  1.7107261876600477\n",
      "116 ) Cost:  1.3728992937981188\n",
      "117 ) Cost:  1.3699034518817612\n",
      "118 ) Cost:  1.369825459195764\n",
      "119 ) Cost:  1.3670119755657857\n",
      "120 ) Cost:  1.3728794079077555\n",
      "121 ) Cost:  1.3672182000219837\n",
      "122 ) Cost:  1.3670936051091171\n",
      "123 ) Cost:  1.3669378897063615\n",
      "124 ) Cost:  1.3655677473009105\n",
      "125 ) Cost:  1.3649861904048386\n",
      "126 ) Cost:  1.3649165032081654\n",
      "127 ) Cost:  1.3667623621265654\n",
      "128 ) Cost:  1.3648676154324204\n",
      "129 ) Cost:  1.3645142274991957\n",
      "130 ) Cost:  1.393352533942252\n",
      "131 ) Cost:  1.3658904071475653\n",
      "132 ) Cost:  1.3645446252043618\n",
      "133 ) Cost:  1.3645037924537666\n",
      "134 ) Cost:  1.3645152452115195\n",
      "135 ) Cost:  1.364501780207703\n",
      "136 ) Cost:  1.3645068509040548\n",
      "137 ) Cost:  1.3664300335169592\n",
      "138 ) Cost:  1.3645100478562044\n",
      "139 ) Cost:  1.3644710978987535\n",
      "140 ) Cost:  1.3651312693422086\n",
      "141 ) Cost:  1.3643000386886799\n",
      "142 ) Cost:  1.3655121565411243\n",
      "143 ) Cost:  1.3645354872146003\n",
      "144 ) Cost:  1.3643123696548998\n",
      "145 ) Cost:  1.3643010623725458\n",
      "146 ) Cost:  1.3643002070192989\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-d603c91decb2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#nn.backProp()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnn_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtheta1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtheta1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'F'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtheta2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtheta2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'F'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtheta1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtheta1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtheta2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnn_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-85-a94f064e733a>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, theta1, theta2, nn_params, X, y)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0mmyargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_layer_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_reg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcostFunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnn_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmyargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'disp'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'maxiter'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"L-BFGS-B\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[0mnn_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"x\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    485\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m--> 487\u001b[1;33m                                 callback=callback, **options)\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[1;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m             \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[1;34m(*wrapper_args)\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-85-a94f064e733a>\u001b[0m in \u001b[0;36mcostFunction\u001b[1;34m(self, nn_params, ils, hls, num_labels, X, y, lam)\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJ\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcost_no_reg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackProp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\") Cost: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-85-a94f064e733a>\u001b[0m in \u001b[0;36mbackProp\u001b[1;34m(self, theta1, theta2)\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0ma1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m             \u001b[0mz2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nn = Neural_Network(X_train, y_train)\n",
    "nn.randInit(X_train, y_train)\n",
    "#print(nn.costFunction())\n",
    "#nn.backProp()\n",
    "nn_params = np.concatenate((nn.theta1.reshape(nn.theta1.size, order='F'), nn.theta2.reshape(nn.theta2.size, order='F')))\n",
    "theta1, theta2 = nn.train(nn.theta1, nn.theta2, nn_params, X_train, y_train.T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
