{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load (downloaded if needed) the MNIST dataset\n",
    "\n",
    "train = pd.read_csv('./datasets/train.csv')\n",
    "test = pd.read_csv('./datasets/test.csv')\n",
    "\n",
    "#y_train = np.array(df['label'].values)\n",
    "#print(y_train)\n",
    "\n",
    "X_train = (train.iloc[:,1:].values.astype('float32'))\n",
    "y_train = (train.iloc[:,0].values.astype('int32'))\n",
    "y_train = np.tile(y_train, (1, 1))\n",
    "X_test = test.values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network:\n",
    "    def __init__(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.m = X_train.shape[0]\n",
    "        self.input_layer_size = X_train.shape[1]\n",
    "        self.hidden_layer_size = 25\n",
    "        self.output_layer_size = 10\n",
    "        self.epsilon = []\n",
    "        self.theta1 = 0\n",
    "        self.theta2 = 0\n",
    "        self.J = 0\n",
    "        self.grad = 0\n",
    "        self.num_labels = 10\n",
    "        \n",
    "    def randInit(self, X, y):\n",
    "        ils = self.input_layer_size\n",
    "        hls = self.hidden_layer_size\n",
    "        ols = self.output_layer_size\n",
    "        \n",
    "        L_in = ils\n",
    "        L_out = hls\n",
    "        \n",
    "        self.epsilon.append(math.sqrt(6) / math.sqrt(L_in + L_out))\n",
    "        \n",
    "        L_in = hls\n",
    "        L_out = ols\n",
    "        \n",
    "        self.epsilon.append(math.sqrt(6) / math.sqrt(L_in + L_out))\n",
    "        \n",
    "        #The theta values are of the form S(j + 1) x S(j) + 1 where S(j) i sthe size of the layer at j\n",
    "        \n",
    "        self.theta1 = np.dot(np.random.rand(hls, ils + 1), (2 * self.epsilon[0])) - self.epsilon[0]\n",
    "        \n",
    "        self.theta2 = np.dot(np.random.rand(ols, hls + 1), (2 * self.epsilon[1])) - self.epsilon[1]\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        return ( 1/(1 + np.exp(-z)))\n",
    "    \n",
    "    def sigmoidPrime(self, z):\n",
    "        return np.multiply(z, (1-z))\n",
    "    \n",
    "    def costFunction(self):\n",
    "        X = self.X_train\n",
    "        y = self.y_train\n",
    "        y = y.T\n",
    "        \n",
    "        #Foward propogation\n",
    "        a1 = np.hstack((np.ones((self.m, 1)), X ))\n",
    "        \n",
    "        z2 = np.dot(a1, np.transpose(self.theta1))\n",
    "        \n",
    "        a2 = self.sigmoid(z2)\n",
    "        a2 = np.hstack((np.ones((a2.shape[0], 1)), a2))\n",
    "        \n",
    "        z3 = np.dot(a2, np.transpose(self.theta2))\n",
    "        \n",
    "        a3 = self.sigmoid(z3)\n",
    "        \n",
    "        #Cost function\n",
    "        \n",
    "        numLabels_temp = np.tile([i for i in range(10)], (self.m, 1) )\n",
    "        \n",
    "        yMatrix_temp = np.tile(y, (1,self.num_labels) )\n",
    "        \n",
    "        yMatrix = np.equal(numLabels_temp, yMatrix_temp)\n",
    "        \n",
    "        cost_no_reg = np.sum(np.multiply(yMatrix, np.log(a3)) + np.multiply((1-yMatrix), np.log(1 - a3)))\n",
    "        \n",
    "        lam = 0\n",
    "        \n",
    "        reg = (lam / (2*self.m)) * ((np.sum(np.square(self.theta1[:, 2:None])) + np.sum(np.square(self.theta2[:, 2:None])))) ** 2\n",
    "        \n",
    "        J =  cost_no_reg + reg\n",
    "        \n",
    "        return J\n",
    "        \n",
    "    def backProp(self):\n",
    "        X = self.X_train\n",
    "        y = self.y_train\n",
    "        y = y.T\n",
    "        lam = 0\n",
    "        \n",
    "        numLabels_temp = np.tile([i for i in range(10)], (self.m, 1) )\n",
    "        \n",
    "        yMatrix_temp = np.tile(y, (1,self.num_labels) )\n",
    "        \n",
    "        yMatrix = np.equal(numLabels_temp, yMatrix_temp)\n",
    "        \n",
    "        delta2 = 0\n",
    "        delta1 = 0\n",
    "        \n",
    "        for i in range(0, 5):\n",
    "            \n",
    "            a1 = np.append(1, X[i, :] )\n",
    "            a1 = a1.reshape(1, a1.size)\n",
    "        \n",
    "            z2 = np.dot(a1, self.theta1.T)\n",
    "\n",
    "            a2 = self.sigmoid(z2)\n",
    "            a2 = np.append(1, a2)\n",
    "            a2 = a2.reshape(1, a2.size)\n",
    "\n",
    "            z3 = np.dot(a2, np.transpose(self.theta2))\n",
    "\n",
    "            a3 = self.sigmoid(z3)\n",
    "            a3 = a3.reshape(1, a3.size)\n",
    "            \n",
    "            yMatrix_i = yMatrix[i, :]\n",
    "            yMatrix_i.reshape(1, yMatrix_i.size)\n",
    "            \n",
    "            delta3_i = np.subtract(a3, yMatrix_i)\n",
    "            \n",
    "            g2 = self.sigmoidPrime(np.insert(z2, 0, 1))\n",
    "            g2 = g2.reshape(1, g2.size)\n",
    "            \n",
    "            delta2_i = np.multiply(np.dot(self.theta2.T, delta3_i.T), g2.T)\n",
    "            delta2_i = delta2_i[1:, :].T\n",
    "            \n",
    "            delta2 = delta2 + np.dot(delta3_i.T, a2)\n",
    "            \n",
    "            delta1 = delta1 + np.dot(delta2_i.T, a1)\n",
    "            \n",
    "        theta1_no_bias = np.multiply((lam/self.m), self.theta1[:, 1:])\n",
    "        theta2_no_bias = np.multiply((lam/self.m), self.theta2[:, 1:])\n",
    "        \n",
    "        theta1_bias = np.multiply((1/self.m), delta1[:, 1])\n",
    "        theta1_bias = theta1_bias.reshape(theta1_bias.size, 1)\n",
    "        \n",
    "        theta2_bias = np.multiply((1/self.m), delta2[:, 1])\n",
    "        theta2_bias = theta2_bias.reshape(theta2_bias.size, 1)\n",
    "        \n",
    "        Theta1_grad = np.concatenate((theta1_bias, np.add(np.multiply((1/self.m), delta1[:, 1:]), theta1_no_bias)), axis=1)\n",
    "        Theta2_grad = np.concatenate((theta2_bias, np.add(np.multiply((1/self.m), delta2[:, 1:]), theta2_no_bias)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn = Neural_Network(X_train, y_train)\n",
    "nn.randInit(X_train, y_train)\n",
    "nn.costFunction()\n",
    "nn.backProp()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
